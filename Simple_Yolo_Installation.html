<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<title></title>
	<meta name="generator" content="LibreOffice 25.8.4.2 (Windows)"/>
	<meta name="created" content="2026-02-08T15:07:57.469242500"/>
	<meta name="changed" content="2026-02-08T15:15:47.443909800"/>
	<style type="text/css">
		@page { size: 8.5in 11in; margin: 0.79in }
		p { line-height: 115%; margin-bottom: 0.1in; background: transparent }
		h1 { margin-bottom: 0.08in; background: transparent; page-break-after: avoid }
		h1.western { font-family: "Liberation Serif", serif; font-weight: bold; font-size: 24pt }
		h1.cjk { font-size: 24pt; font-family: "NSimSun"; font-weight: bold }
		h1.ctl { font-family: "Arial"; font-size: 24pt; font-weight: bold }
		h2 { margin-top: 0.14in; margin-bottom: 0.08in; background: transparent; page-break-after: avoid }
		h2.western { font-family: "Liberation Serif", serif; font-weight: bold; font-size: 18pt }
		h2.cjk { font-size: 18pt; font-family: "NSimSun"; font-weight: bold }
		h2.ctl { font-family: "Arial"; font-size: 18pt; font-weight: bold }
		pre { background: transparent }
		pre.western { font-family: "Liberation Mono", monospace; font-size: 10pt }
		pre.cjk { font-size: 10pt; font-family: "NSimSun", monospace }
		pre.ctl { font-family: "Liberation Mono", monospace; font-size: 10pt }
		blockquote { margin-left: 0.39in; margin-right: 0.39in; background: transparent }
		h3 { margin-top: 0.1in; margin-bottom: 0.08in; background: transparent; page-break-after: avoid }
		h3.western { font-family: "Liberation Serif", serif; font-weight: bold; font-size: 14pt }
		h3.cjk { font-size: 14pt; font-family: "NSimSun"; font-weight: bold }
		h3.ctl { font-family: "Arial"; font-size: 14pt; font-weight: bold }
		td p { orphans: 0; widows: 0; background: transparent }
		th p { font-weight: bold; text-align: center; orphans: 0; widows: 0; background: transparent }
		code.western { font-family: "Liberation Mono", monospace }
		code.cjk { font-family: "NSimSun", monospace }
		code.ctl { font-family: "Liberation Mono", monospace }
		strong { font-weight: bold }
	</style>
</head>
<body lang="en-US" link="#000080" vlink="#800000" dir="ltr"><h1 class="western">
Simple YOLO Inference Server 
</h1>
<h1 class="western"><font size="5" style="font-size: 18pt">Installation
&amp; Setup Guide</font></h1>
<p>A lightweight, locally-hosted YOLOv8 server using
FastAPI.<br/>
Supports CPU, Maxwell GPUs (GTX 970/980), modern NVIDIA
GPUs (RTX 30/40), and Windows/Linux environments.</p>
<hr/>

<h2 class="western"> 1)  Directory Setup</h2>
<p>Create the server and model directories:</p>
<pre class="western"><code class="western">sudo mkdir -p /opt/siyolo/models</code>
<code class="western">cd /opt/siyolo</code></pre>
<ul>
	<li><p><code class="western">models/</code> stores YOLO model
	weights.</p></li>
</ul>
<hr/>

<h2 class="western">2) Python Virtual Environment</h2>
<pre class="western"><code class="western">python3 -m venv ./venv</code>
<code class="western">source ./venv/bin/activate   # Linux/macOS</code>
<code class="western">pip install --upgrade pip</code></pre><blockquote>
⚠ Linux: Use Python 3.10 for older CPUs/Maxwell GPUs. Windows can
use Python 3.10–3.12.</blockquote>
<hr/>

<h2 class="western">3) Install Requirements</h2>
<h3 class="western">a) Modern GPUs / New CPUs (CUDA 12.1+)</h3>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">pip install torch torchvision numpy ultralytics fastapi uvicorn opencv-python python-multipart --index-url https://download.pytorch.org/whl/cu121</code></pre><h3 class="western">
b) Maxwell GPUs (GTX 970 / 980, CUDA 11.7)</h3>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 numpy ultralytics==8.0.200 fastapi uvicorn opencv-python python-multipart --index-url https://download.pytorch.org/whl/cu117</code></pre><h3 class="western">
c) Older CPUs (no AVX2 / AVX512)</h3>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 numpy==1.24.4 ultralytics==8.0.200 fastapi uvicorn opencv-python python-multipart --index-url https://download.pytorch.org/whl/cu117</code></pre>
<hr/>

<h2 class="western">4) Extract Server Files</h2>
<p>If you have a tarball:</p>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">tar -xzvf siyolo.tar.gz -C /opt/siyolo</code></pre>
<hr/>

<h2 class="western">5) Create System User (Linux Only)</h2>
<pre class="western"><code class="western">sudo useradd -r siyolo</code>
<code class="western">sudo chown -R siyolo:siyolo /opt/siyolo</code></pre><blockquote>
Server runs under a dedicated user for security.</blockquote>
<hr/>

<h2 class="western">6) Configure systemd Service (Linux Only)</h2>
<p>Create <code class="western">/opt/siyolo/siyolo.service</code>:</p>
<pre class="western"><code class="western">[Unit]</code>
<code class="western">Description=A Simple YOLO Inference Server</code>
<code class="western">After=network.target</code>

<code class="western">[Service]</code>
<code class="western">Type=simple</code>
<code class="western">User=siyolo</code>
<code class="western">Group=siyolo</code>
<code class="western">WorkingDirectory=/opt/siyolo</code>
<code class="western">ExecStart=/opt/siyolo/venv/bin/python3.10 -u /opt/siyolo/main.py</code>
<code class="western">Restart=always</code>
<code class="western">RestartSec=5</code>

<code class="western"># Environment</code>
<code class="western">Environment=&quot;TMPDIR=/dev/shm&quot;</code>
<code class="western">Environment=&quot;PYTHONUNBUFFERED=1&quot;</code>
<code class="western">Environment=&quot;YOLO_MODEL=yolov8x.pt&quot;</code>
<code class="western">Environment=&quot;YOLO_VERBOSE=False&quot;</code>

<code class="western"># Prevent CPU oversubscription</code>
<code class="western">Environment=OMP_NUM_THREADS=1</code>
<code class="western">Environment=OPENBLAS_NUM_THREADS=1</code>
<code class="western">Environment=MKL_NUM_THREADS=1</code>
<code class="western">Environment=NUMEXPR_NUM_THREADS=1</code>

<code class="western"># Optional limits</code>
<code class="western">NoNewPrivileges=true</code>
<code class="western">PrivateTmp=true</code>
<code class="western">ProtectSystem=full</code>
<code class="western">ProtectHome=true</code>

<code class="western">[Install]</code>
<code class="western">WantedBy=multi-user.target</code></pre><p>
Enable and start:</p>
<pre class="western"><code class="western">sudo ln -s /opt/siyolo/siyolo.service /etc/systemd/system/siyolo.service</code>
<code class="western">sudo systemctl daemon-reload</code>
<code class="western">sudo systemctl enable siyolo</code>
<code class="western">sudo systemctl start siyolo</code>
<code class="western">sudo systemctl status siyolo</code></pre>
<hr/>

<h2 class="western">7) Testing the Server (Linux &amp; Windows)</h2>
<p>Activate venv and run manually first:</p>
<pre class="western"><code class="western">source /opt/siyolo/venv/bin/activate  # Linux</code>
<code class="western">python3.10 main.py</code></pre><p>
Expected output:</p>
<pre class="western"><code class="western">Starting Simple YOLO server v1.0, listening on 0.0.0.0:32168</code>
<code class="western">Torch version: 1.13.1+cu117 (CUDA: 11.7)</code>
<code class="western">Running model yolov8x.pt on CUDA (NVIDIA GeForce GTX 970)</code></pre>
<ul>
	<li><p>Use <code class="western">curl</code> or your client to POST
	images for inference.</p></li>
	<li><p>Supports <code class="western">multipart/form-data</code> and
	<code class="western">application/json</code> (base64).</p></li>
	<li><p>Honor <code class="western">min_confidence</code> from client
	requests.</p></li>
</ul>
<hr/>

<h2 class="western">8) Windows 11 Setup (RTX 4090)</h2>
<h3 class="western">a) Install Python &amp; venv</h3>
<pre class="western"><code class="western"># Install Python 3.10+ and add to PATH</code>
<code class="western">python -m venv C:\siyolo\venv</code>
<code class="western">C:\siyolo\venv\Scripts\activate</code>
<code class="western">python -m pip install --upgrade pip</code></pre><h3 class="western">
b) Install Requirements (CUDA 12.x)</h3>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">pip install torch torchvision numpy ultralytics fastapi uvicorn opencv-python python-multipart --index-url https://download.pytorch.org/whl/cu121</code></pre><h3 class="western">
c) Place Server Files</h3>
<pre class="western"><code class="western">mkdir C:\siyolo\models</code>
<code class="western"># Extract or copy main.py and other server files to C:\siyolo</code></pre><h3 class="western">
d) Run Server Manually</h3>
<pre class="western" style="margin-bottom: 0.2in"><code class="western">python main.py</code></pre>
<ul>
	<li><p>Verify server listens on port <code class="western">32168</code>.</p></li>
</ul>
<h3 class="western">e) Optional: Run as Service (Windows)</h3>
<p>Use <strong>NSSM</strong> or <strong>Task Scheduler</strong>:</p>
<ul>
	<li><p>NSSM: <code class="western">nssm install siyolo
	&quot;C:\siyolo\venv\Scripts\python.exe&quot; &quot;C:\siyolo\main.py&quot;</code></p></li>
	<li><p>Set <code class="western">Restart on failure</code>, working
	directory <code class="western">C:\siyolo</code>.</p></li>
</ul>
<hr/>

<h2 class="western">9) Notes &amp; Tips</h2>
<ul>
	<li><p><strong>Models</strong>: Place YOLO <code class="western">.pt</code>
	files in <code class="western">/opt/siyolo/models/</code>.</p></li>
	<li><p><strong>CPU Display</strong>: Falls back to system CPU if no
	CUDA.</p></li>
	<li><p><strong>FP16</strong>: Use <code class="western">half=True</code>
	on CUDA for lower VRAM usage.</p></li>
	<li><p><strong>Threading</strong>: <code class="western">OMP_NUM_THREADS=1</code>
	is safe for dual-core; increase for multi-core CPUs.</p></li>
	<li><p><strong>VRAM</strong>: Large models (<code class="western">yolov8x-seg.pt</code>)
	may require &gt;3–4GB. Consider smaller models (<code class="western">yolov8n</code>,
	<code class="western">yolov8m</code>) for 4GB GPUs.</p></li>
	<li><p><strong>Debug Logs</strong>: Controlled via
	<code class="western">YOLO_VERBOSE=True/False</code>.</p></li>
</ul>
<p style="margin-bottom: 0in; line-height: 100%"><br/>

</p>
<p style="margin-bottom: 0in; line-height: 100%"><br/>

</p>
<table width="665" cellpadding="2" cellspacing="0">
	<col width="107"/>
	<col width="55"/>
	<col width="64"/>
	<col width="94"/>
	<col width="68"/>
	<col width="253"/>
	<thead>
		<tr>
			<th width="107" style="border: none; padding: 0in"><p>Model</p>
			</th>
			<th width="55" style="border: none; padding: 0in"><p>Params</p>
			</th>
			<th width="64" style="border: none; padding: 0in"><p>GFLOPs</p>
			</th>
			<th width="94" style="border: none; padding: 0in"><p>Typical VRAM
				(FP32)</p>
			</th>
			<th width="68" style="border: none; padding: 0in"><p>FP16 VRAM</p>
			</th>
			<th width="253" style="border: none; padding: 0in"><p>Notes /
				Performance</p>
			</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8n.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>3.2M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>8.5</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~0.5 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~0.25 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Nano, very
				fast, suitable for low-VRAM GPUs; good for 5–15 FPS at 720p</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8s.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>11M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>27</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~1 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~0.5 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Small, good
				speed/accuracy tradeoff; 5–20 FPS on GTX 970</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8m.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>25M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>89</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~2 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~1 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Medium,
				balanced speed/accuracy; fits GTX 970 4GB VRAM with FP16</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8l.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>46M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>182</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~3.5 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~1.75 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Large,
				slower; may struggle on 4GB VRAM cards</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8x.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>68M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>258</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~5 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~2.5 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Extra-large,
				best accuracy; requires high-VRAM GPU or CPU fallback</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8n-seg.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>3.6M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>11</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~0.7 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~0.35 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Nano with
				segmentation masks, very fast</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8m-seg.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>28M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>95</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~2.2 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~1.1 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Medium
				segmentation model, balanced speed/accuracy</p>
			</td>
		</tr>
		<tr>
			<td width="107" style="border: none; padding: 0in"><p><strong>yolov8x-seg.pt</strong></p>
			</td>
			<td width="55" style="border: none; padding: 0in"><p>69M</p>
			</td>
			<td width="64" style="border: none; padding: 0in"><p>265</p>
			</td>
			<td width="94" style="border: none; padding: 0in"><p>~5.2 GB</p>
			</td>
			<td width="68" style="border: none; padding: 0in"><p>~2.6 GB</p>
			</td>
			<td width="253" style="border: none; padding: 0in"><p>Large
				segmentation, high VRAM; slow on GTX 970, fast on RTX 4090</p>
			</td>
		</tr>
	</tbody>
</table>
<p style="margin-bottom: 0in; line-height: 100%"><br/>

</p>
</body>
</html>